# Story 3.2: Risk Scoring Agent

## Status
DONE

## Story
**As a** Developer,
**I want** To implement the **Risk Scoring Agent** using LangChain and ReAct pattern,
**So that** The system can assign risk scores to extracted clauses based on defined rules and heuristics.

## Acceptance Criteria
1. Agent implemented as distinct module in `backend/app/agents/risk_scoring.py`
2. Takes Clause Extraction Agent output as input
3. Applies defined risk scoring rules and heuristics
4. Outputs data enriched with risk scores and risk categories
5. Agent is independently testable with unit tests
6. Includes code to facilitate display of internal LangGraph visualization
7. Follows ReAct pattern for reasoning and action

## Tasks / Subtasks

- [x] Task 1: Set Up Agent Module Structure (AC: 1)
  - [x] Create `backend/app/agents/risk_scoring.py` module
  - [x] Define RiskScoringAgent class
  - [x] Set up agent configuration and initialization
  - [x] Import required LangChain components (ReAct, tools, prompts)
  - [x] Add type hints and docstrings

- [x] Task 2: Define Risk Scoring Rules and Heuristics (AC: 3)
  - [x] Define risk scoring criteria for each clause type
  - [x] Create risk scoring matrix (clause type √ó risk factors)
  - [x] Define numerical risk scores (0-100 scale)
  - [x] Define risk categories (Low: 0-25, Medium: 26-50, High: 51-75, Critical: 76-100)
  - [x] Document risk scoring methodology

- [x] Task 3: Define Agent Tools (AC: 3)
  - [x] Create clause analysis tool for evaluating clause characteristics
  - [x] Create risk calculation tool for computing risk scores
  - [x] Create risk categorization tool for assigning risk levels
  - [x] Define tool schemas and descriptions for ReAct agent
  - [x] Add error handling for tool execution

- [x] Task 4: Implement LangGraph ReAct Logic (AC: 1, 7)
  - [x] Set up LangGraph with create_react_agent
  - [x] Define agent tools with clear descriptions
  - [x] Implement reasoning step using GPT-4o-mini
  - [x] Implement action step with tool execution
  - [x] Implement observation step to process results
  - [x] Add automatic tool looping via create_react_agent
  - [x] Configure max iterations (recursion_limit: 50)
  - [x] Add LangSmith tracing support

- [x] Task 5: Define Output Data Models (AC: 4)
  - [x] Create Pydantic models in `backend/app/models/agent.py` for:
    - RiskFactor (factor_name, description, score_impact, detected)
    - RiskScore (score, category, factors, justification)
    - ScoredClause (clause, risk_score)
    - RiskScoringResult (scored_clauses, overall_risk_score, overall_risk_category, metadata)
  - [x] Add validation rules for output structure
  - [x] Ensure JSON serialization compatibility

- [x] Task 6: Implement Risk Scoring Logic (AC: 2, 3, 4)
  - [x] Implement clause characteristic analysis
  - [x] Implement risk factor identification
  - [x] Implement risk score calculation based on rules
  - [x] Implement risk category assignment
  - [x] Generate justification for each risk score
  - [x] Calculate overall document risk score

- [x] Task 7: Add LangGraph Visualization Support (AC: 6)
  - [x] Structure agent logic as LangGraph graph via create_react_agent
  - [x] Define graph nodes automatically via create_react_agent
  - [x] Define graph edges showing agent flow
  - [x] Create helper function to export graph visualization (get_graph_visualization)
  - [x] Add documentation on how to display graph in notebooks
  - [x] Test visualization rendering

- [x] Task 8: Implement Agent Execution Method (AC: 2, 4)
  - [x] Create main `score_risks()` method
  - [x] Accept ClauseExtractionResult as input
  - [x] Execute ReAct agent with proper state management
  - [x] Collect and structure agent outputs via _parse_scoring_results
  - [x] Return RiskScoringResult with all scores
  - [x] Add logging for agent reasoning steps

- [x] Task 9: Add Independent Testing (AC: 5)
  - [x] Create `backend/tests/test_risk_scoring.py`
  - [x] Test agent initialization and configuration
  - [x] Test risk scoring rules with known clauses
  - [x] Test risk categorization accuracy
  - [x] Test overall risk calculation
  - [x] Test complete agent execution end-to-end
  - [x] Test error handling and edge cases
  - [x] Mock LLM calls to avoid API costs in tests
  - [x] Ensure all tests pass (21/21 passing)

- [x] Task 10: Add Documentation and Examples (AC: 1, 6)
  - [x] Document risk scoring methodology in docstrings
  - [x] Provide usage examples in docstrings
  - [x] Document input/output formats
  - [x] Document risk scoring rules and heuristics (RISK_RULES constant)
  - [x] Add inline code comments for complex logic
  - [x] Add comprehensive module and class docstrings

## Dev Notes

### Architecture Context

**Agent Location:** `backend/app/agents/risk_scoring.py`
[Source: architecture/6-implementation-details.md#62]

**Agent Pattern:** ReAct (Reason -> Act -> Observe) using LangChain
[Source: architecture/6-implementation-details.md#64]

**Input:** ClauseExtractionResult from Story 3.1
**Output:** RiskScoringResult with scored clauses

### Risk Scoring Methodology

**Risk Score Scale:** 0-100
- **0-25:** Low Risk (Green) - Standard terms, minimal concerns
- **26-50:** Medium Risk (Yellow) - Some concerns, review recommended
- **51-75:** High Risk (Orange) - Significant concerns, negotiation needed
- **76-100:** Critical Risk (Red) - Major concerns, immediate attention required

**Risk Factors by Clause Type:**

**Payment Terms (Weight: High)**
- Unusual payment structure: +20
- Delayed payment terms: +15
- Inadequate escrow: +25
- Vague earnout provisions: +20
- No payment security: +30

**Warranties (Weight: Critical)**
- Missing material warranties: +40
- Short survival period (<12 months): +30
- Broad carve-outs: +25
- Weak disclosure requirements: +20

**Indemnification (Weight: Critical)**
- Unlimited liability: +50
- No cap on indemnification: +40
- Low basket threshold: +15
- Broad indemnification scope: +25
- Short survival period: +20

**Termination (Weight: High)**
- Unfavorable termination rights: +25
- High termination fees: +20
- Vague termination conditions: +15
- Unbalanced termination rights: +30

**Confidentiality (Weight: Medium)**
- Weak confidentiality terms: +20
- Short confidentiality period: +15
- Broad disclosure exceptions: +25
- No return/destruction clause: +10

**Non-Compete (Weight: High)**
- Overly broad scope (>5 years): +35
- Global geographic scope: +30
- Vague restricted activities: +20
- No reasonable limitations: +25

**Dispute Resolution (Weight: Medium)**
- Unfavorable venue: +15
- No arbitration clause: +10
- Unclear governing law: +20
- No attorney fees provision: +5

### LLM Configuration

**Model:** OpenAI GPT-4o-mini
**Tracing:** LangSmith enabled
**Framework:** LangGraph with StateGraph
[Source: architecture/3-tech-stack.md]

### Required Tools

The agent needs three main capabilities:
1. **Clause Analysis** - Evaluate clause characteristics for risk factors
2. **Risk Calculation** - Compute risk scores based on defined rules
3. **Risk Categorization** - Assign risk levels (Low/Medium/High/Critical)

### Data Models

**Required Pydantic Models:** (in `backend/app/models/agent.py`)
- `RiskFactor` - Individual risk factor with score impact
- `RiskScore` - Complete risk assessment for a clause
- `ScoredClause` - Clause with attached risk score
- `RiskScoringResult` - Complete agent output with all scored clauses

### Integration Points

**Input:** ClauseExtractionResult from Story 3.1
**Output:** RiskScoringResult with scored clauses and overall risk assessment

## Testing

**Test Location:** `backend/tests/test_risk_scoring.py`

**Test Coverage Requirements:**
- Agent initialization and configuration
- Risk scoring rules accuracy
- Risk categorization correctness
- Overall risk calculation
- Complete end-to-end agent execution
- Error handling and edge cases
- LangGraph visualization generation

**Testing Framework:** Pytest (per architecture/3-tech-stack.md)

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-20 | 1.0 | Initial story creation for Epic 3 | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
Claude 3.5 Sonnet (via Cline)

### Debug Log References
None - All tests passed successfully.

### Completion Notes List
- Implemented RiskScoringAgent using `langgraph.prebuilt.create_react_agent()` following the pattern from Story 3.1
- Created comprehensive Pydantic data models for risk scoring (RiskFactor, RiskScore, ScoredClause, RiskScoringResult)
- Implemented three agent tools: analyze_clause_characteristics, calculate_risk_score, generate_risk_justification
- Defined comprehensive risk scoring rules for 7 clause types with specific risk factors and impact scores
- Risk scores range from 0-100 with categories: Low (0-25), Medium (26-50), High (51-75), Critical (76-100)
- Added LangGraph visualization support with get_graph_visualization() method
- Created comprehensive test suite with 21 tests covering all functionality, all passing
- Fixed datetime deprecation warnings by using datetime.now(UTC) instead of datetime.utcnow()
- Fixed parsing logic to handle both wrapped (```json```) and raw JSON in ToolMessages
- Validated with E04 notebook: Successfully scored 3/3 clauses with overall risk 65/100 (High)
- All acceptance criteria met and validated

### Implementation Pattern for Future Agents (Stories 3.3-3.5)

**Key Architecture Decision: Use `langgraph.prebuilt.create_react_agent()`**

This pattern enables autonomous agents that loop through tools automatically:

```python
from langgraph.prebuilt import create_react_agent

# 1. Create tools with CLEAR descriptions
tools = [
    Tool(
        name="tool_name",
        description="Clear description with explicit input/output format like: Input must be valid JSON string like: {{\"key\": \"value\"}}",
        func=tool_function
    )
]

# 2. Create agent (handles looping automatically)
agent_executor = create_react_agent(model=llm, tools=tools)

# 3. Invoke with recursion limit and stopping instruction
result = agent_executor.invoke(
    {"messages": [HumanMessage(content="Task with STOP condition")]},
    config={"recursion_limit": 50}
)

# 4. Parse results from messages with validation
for msg in result.get("messages", []):
    # Extract JSON - handle BOTH formats:
    # - Wrapped: ```json {...} ```
    # - Raw: {...} (common in ToolMessage)
```

**Critical Success Factors:**
1. **Tool Descriptions**: Must be explicit about input format with examples
2. **Stopping Instructions**: Include clear stopping condition in prompt (e.g., "STOP after analyzing X items")
3. **Recursion Limit**: Set to 50 for complex tasks (default 25 may be too low)
4. **JSON Parsing**: Handle BOTH wrapped (```json```) and raw JSON formats from ToolMessages
5. **Message Types**: ToolMessage often contains raw JSON, AIMessage may contain wrapped JSON

**Parsing Pattern (CRITICAL FIX from Story 3.2):**
```python
# Extract JSON from messages - handle both formats
for msg in messages:
    content = str(msg.content)
    
    # Try wrapped format: ```json {...} ```
    json_matches = re.findall(r'```json\s*(\{.*?\}|\[.*?\])\s*```', content, re.DOTALL)
    for json_str in json_matches:
        parsed = json.loads(json_str)
        # Process parsed data
    
    # Try raw format (common in ToolMessage)
    if content.strip().startswith('{') or content.strip().startswith('['):
        try:
            parsed = json.loads(content.strip())
            # Process parsed data
        except json.JSONDecodeError:
            pass  # Not valid JSON
```

**Performance Characteristics:**
- ~15-20 messages for 3 items
- ~40-50 seconds processing time
- Autonomous tool looping without manual orchestration

**Benefits Over Custom Graph:**
- ‚úÖ Automatic tool looping (agent ‚ü∑ tools cycle)
- ‚úÖ Built-in stopping logic
- ‚úÖ Less code to maintain
- ‚úÖ Proven, battle-tested pattern
- ‚úÖ Ready for orchestrator integration in Epic 4

### File List
**Created:**
- backend/app/agents/risk_scoring.py - Risk scoring agent using create_react_agent
- backend/tests/test_risk_scoring.py - Comprehensive test suite (21 tests)
- notebooks/E04_Risk_Scoring_Agent.py - Jupytext demo notebook showing agent in action

**Modified:**
- backend/app/models/agent.py - Added RiskFactor, RiskScore, ScoredClause, RiskScoringResult models

## QA Results

### Review Date: 2025-10-21

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

**Overall Assessment: EXCELLENT** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

The Risk Scoring Agent implementation demonstrates exceptional quality across all dimensions:

1. **Architecture Excellence**: Properly uses `langgraph.prebuilt.create_react_agent()` following the established pattern from Story 3.1, enabling autonomous tool looping without manual orchestration.

2. **Clean Code**: Well-structured, readable code with comprehensive docstrings, type hints, and clear separation of concerns. The RISK_RULES constant provides excellent documentation of the scoring methodology.

3. **Robust Error Handling**: Comprehensive try-catch blocks in all tool methods with proper logging and graceful degradation.

4. **Test Coverage**: Exceptional - 21/21 tests passing with comprehensive coverage of initialization, tools, risk categories, end-to-end execution, error handling, and data models.

5. **Documentation**: Outstanding - detailed docstrings, inline comments, comprehensive notebook demo, and well-documented risk scoring rules.

### Refactoring Performed

**No refactoring needed** - The code is already at production quality. The implementation follows best practices and maintains consistency with the established codebase patterns.

### Compliance Check

- ‚úÖ **Coding Standards**: Fully compliant - proper type hints, docstrings, error handling, logging
- ‚úÖ **Project Structure**: Correct placement in `backend/app/agents/`, proper module organization
- ‚úÖ **Testing Strategy**: Excellent - 21 comprehensive tests with mocking, edge cases, and integration tests
- ‚úÖ **All ACs Met**: All 7 acceptance criteria fully satisfied with evidence

### Acceptance Criteria Validation

1. ‚úÖ **AC1 - Distinct Module**: Agent implemented in `backend/app/agents/risk_scoring.py` with clear class structure
2. ‚úÖ **AC2 - Takes Clause Extraction Output**: Accepts `ClauseExtractionResult` as input parameter
3. ‚úÖ **AC3 - Applies Risk Scoring Rules**: Comprehensive RISK_RULES constant with 7 clause types and 30+ risk factors
4. ‚úÖ **AC4 - Outputs Enriched Data**: Returns `RiskScoringResult` with scored clauses, overall risk, and metadata
5. ‚úÖ **AC5 - Independently Testable**: 21/21 tests passing with comprehensive coverage
6. ‚úÖ **AC6 - LangGraph Visualization**: `get_graph_visualization()` method implemented and tested
7. ‚úÖ **AC7 - ReAct Pattern**: Uses `create_react_agent` with proper tool definitions and autonomous looping

### Requirements Traceability

**Given** a ClauseExtractionResult with extracted clauses  
**When** the Risk Scoring Agent processes the clauses  
**Then** it should:
- ‚úÖ Analyze each clause for risk characteristics (Tool: analyze_clause_characteristics)
- ‚úÖ Calculate numerical risk scores 0-100 (Tool: calculate_risk_score)
- ‚úÖ Assign risk categories (Low/Medium/High/Critical) (Validated in tests)
- ‚úÖ Generate justifications for scores (Tool: generate_risk_justification)
- ‚úÖ Return structured RiskScoringResult (Validated in tests and notebook)

### Test Architecture Assessment

**Test Coverage: COMPREHENSIVE** (21 tests)

**Test Distribution:**
- Initialization & Configuration: 2 tests ‚úÖ
- Individual Tool Testing: 7 tests ‚úÖ
- Risk Category Logic: 4 tests ‚úÖ
- End-to-End Execution: 3 tests ‚úÖ
- Data Model Validation: 4 tests ‚úÖ
- Graph Visualization: 1 test ‚úÖ

**Test Quality Highlights:**
- ‚úÖ Proper mocking of LLM calls to avoid API costs
- ‚úÖ Edge case coverage (empty clauses, invalid JSON, unknown types)
- ‚úÖ Score capping validation (ensures scores don't exceed 100)
- ‚úÖ Error handling verification
- ‚úÖ All risk categories tested (Low/Medium/High/Critical)

**Test Level Appropriateness:**
- Unit tests for individual tools ‚úÖ
- Integration tests for agent execution ‚úÖ
- Data model validation tests ‚úÖ
- Appropriate use of mocks for external dependencies ‚úÖ

### Non-Functional Requirements (NFRs)

**Security: PASS** ‚úÖ
- API keys properly managed via settings
- No hardcoded credentials
- Input validation in all tool methods
- Safe JSON parsing with error handling

**Performance: PASS** ‚úÖ
- Processing time tracked in metadata
- Efficient risk calculation (simple arithmetic)
- Reasonable recursion limit (50) for complex tasks
- ~40-50 seconds for 3 clauses (acceptable for LLM-based processing)

**Reliability: PASS** ‚úÖ
- Comprehensive error handling with graceful degradation
- Returns valid result even on errors (with error in metadata)
- Proper logging throughout execution
- All tests passing consistently

**Maintainability: EXCELLENT** ‚≠ê
- Clear code structure with single responsibility
- Comprehensive documentation
- Type hints throughout
- Easy to extend with new risk rules
- Follows established patterns from Story 3.1

### Testability Evaluation

- ‚úÖ **Controllability**: Excellent - all inputs well-defined, tools mockable
- ‚úÖ **Observability**: Excellent - detailed logging, metadata tracking, clear outputs
- ‚úÖ **Debuggability**: Excellent - comprehensive error messages, logging, test coverage

### Technical Debt Identification

**NONE IDENTIFIED** - This is exemplary implementation with:
- No shortcuts taken
- Complete test coverage
- Comprehensive documentation
- Proper error handling
- Following established patterns

### Security Review

‚úÖ **No security concerns identified**
- API keys managed through configuration
- Input validation present
- No SQL injection risks (no database)
- No XSS risks (backend only)
- Proper error handling prevents information leakage

### Performance Considerations

‚úÖ **Performance is appropriate for use case**
- LLM-based processing inherently takes time (~40-50s for 3 clauses)
- Processing time tracked in metadata for monitoring
- Efficient risk calculation logic
- No unnecessary API calls

**Potential Future Optimization:**
- Consider batch processing for large documents (post-MVP)
- Cache risk rules to avoid repeated LLM calls for similar clauses (post-MVP)

### Files Modified During Review

**None** - No modifications needed. Code is production-ready.

### Implementation Pattern Documentation

The story includes **excellent documentation** of the implementation pattern for future agents (Stories 3.3-3.5):
- ‚úÖ Clear explanation of `create_react_agent` usage
- ‚úÖ Critical success factors documented
- ‚úÖ JSON parsing pattern fix documented
- ‚úÖ Performance characteristics noted
- ‚úÖ Benefits over custom graph explained

This documentation will significantly accelerate development of remaining agents.

### Gate Status

**Gate: PASS** ‚Üí docs/qa/gates/3.2-risk-scoring-agent.yml

**Quality Score: 100/100**

All criteria met with exceptional quality. No issues identified.

### Recommended Status

‚úÖ **Ready for Done**

This story exceeds quality standards and is ready for production use. The implementation is:
- Complete and correct
- Well-tested (21/21 tests passing)
- Thoroughly documented
- Following best practices
- Ready for integration into Epic 4 orchestrator

**Congratulations to the development team on exceptional work!** üéâ
