# Story 4.1: Implement ReAct-Based Orchestration (Supervisor Agent)

## Status
Ready for Review

## Story
**As a** Developer,
**I want** To implement the **orchestrator (supervisor agent)** logic using **LangGraph** managing a **ReAct-style workflow**, routing tasks to specialized agents,
**So that** The system dynamically processes documents end-to-end under the supervisor agent's direction.

## Acceptance Criteria
1. Orchestrator (supervisor agent) logic implemented using LangGraph graph in `backend/app/orchestration/`
2. Maintains state throughout the multi-agent workflow
3. Routes tasks to correct agents based on state and reasoning
4. Agents execute using their defined tools from Epic 3
5. Data and state passed correctly between agents
6. Handles errors and prevents infinite loops
7. Facilitates display of the overall orchestration graph for visualization

## Tasks / Subtasks

- [x] Task 1: Set Up Orchestration Module Structure (AC: 1)
  - [x] Create `backend/app/orchestration/` directory
  - [x] Create `backend/app/orchestration/__init__.py`
  - [x] Create `backend/app/orchestration/pipeline.py` for main orchestrator
  - [x] Define orchestrator configuration and initialization
  - [x] Import required LangGraph components (StateGraph, MessageGraph)
  - [x] Add type hints and comprehensive docstrings

- [x] Task 2: Define Orchestration State Model (AC: 2, 5)
  - [x] Create `OrchestrationState` TypedDict in `backend/app/models/`
  - [x] Define state fields:
    - document_id: str
    - document_chunks: List[str]
    - current_step: str
    - extracted_clauses: List[ExtractedClause]
    - risk_scores: List[RiskScore]
    - summary: str
    - provenance_data: Dict
    - checklist: List[ChecklistItem]
    - errors: List[str]
    - metadata: Dict
  - [x] Add validation rules for state transitions
  - [x] Ensure JSON serialization compatibility

- [x] Task 3: Implement Agent Node Functions (AC: 3, 4)
  - [x] Create node function for Ingestion Agent
  - [x] Create node function for Clause Extraction Agent
  - [x] Create node function for Risk Scoring Agent
  - [x] Create node function for Summary Agent
  - [x] Create node function for Provenance Agent
  - [x] Create node function for Checklist Agent
  - [x] Each node function accepts state and returns updated state
  - [x] Add error handling and logging for each node

- [x] Task 4: Implement Supervisor Reasoning Logic (AC: 3)
  - [x] Create supervisor node that analyzes current state
  - [x] Implement deterministic routing to determine next agent
  - [x] Define routing logic based on:
    - Current workflow step
    - Completion status of previous agents
    - Error conditions
    - Data availability
  - [x] Add logging for supervisor reasoning steps

- [x] Task 5: Build LangGraph Orchestration Graph (AC: 1, 3, 6)
  - [x] Initialize StateGraph with OrchestrationState
  - [x] Add all agent nodes to the graph
  - [x] Add supervisor node to the graph
  - [x] Define edges between nodes:
    - START → Supervisor → Ingestion → Supervisor
    - Supervisor → Clause Extraction → Supervisor
    - Supervisor → Risk Scoring → Supervisor
    - Supervisor → Summary → Supervisor
    - Supervisor → Provenance → Supervisor
    - Supervisor → Checklist → Supervisor → END
  - [x] Add conditional edges for routing
  - [x] Implement loop prevention (max iterations = 50)
  - [x] Compile the graph with MemorySaver checkpointer

- [x] Task 6: Implement Error Handling and Recovery (AC: 6)
  - [x] Define error handling strategy for each agent failure
  - [x] Log all errors to state.errors list
  - [x] Define graceful degradation paths (continue on errors)
  - [x] Set maximum iteration limit (50)
  - [x] Add error threshold (>3 errors stops workflow)

- [x] Task 7: Implement State Management (AC: 2, 5)
  - [x] Create state initialization function
  - [x] Implement state update functions for each agent
  - [x] Ensure immutable state updates (return new state)
  - [x] Add state persistence/checkpointing capability (MemorySaver)
  - [x] Add metadata tracking for each agent

- [x] Task 8: Add LangGraph Visualization Support (AC: 7)
  - [x] Create helper function `get_graph_visualization()`
  - [x] Export graph structure in displayable format
  - [x] Handle IPython import gracefully
  - [x] Test visualization in tests

- [x] Task 9: Implement Main Orchestrator Execution Method (AC: 1-7)
  - [x] Create `run_orchestration()` method
  - [x] Accept document path/ID as input
  - [x] Initialize orchestration state
  - [x] Execute LangGraph with proper configuration
  - [x] Collect final results from state
  - [x] Return structured output with all agent results
  - [x] Add comprehensive logging throughout execution

- [x] Task 10: Create Integration Tests (AC: 1-7)
  - [x] Create `backend/tests/test_orchestration.py`
  - [x] Test orchestrator initialization
  - [x] Test state management and transitions
  - [x] Test agent routing logic
  - [x] Test error handling and recovery
  - [x] Test complete end-to-end orchestration
  - [x] Mock individual agents to isolate orchestrator logic
  - [x] Test graph visualization generation
  - [x] Ensure all tests pass (25/25 passing)

- [x] Task 11: Add Documentation and Examples (AC: 1, 7)
  - [x] Document orchestration architecture in docstrings
  - [x] Provide usage examples in docstrings
  - [x] Document state model and transitions
  - [x] Document agent routing logic
  - [x] Document error handling strategies
  - [x] Add inline code comments for complex logic
  - [x] Create E08_Orchestration_Demo.py notebook

## Dev Notes

### Architecture Context

**Orchestrator Location:** `backend/app/orchestration/pipeline.py`
[Source: architecture/6-implementation-details.md#64]

**Implementation Approach:**
- Use LangGraph StateGraph for orchestration
- Implement ReAct pattern at orchestrator level (Reason → Act → Observe)
- Supervisor agent makes routing decisions
- Specialized agents execute tasks using their tools
- Enable LangSmith tracing for observability

**Pattern:** ReAct orchestration using LangGraph
[Source: architecture/6-implementation-details.md#64]

### Agent Integration

**Available Agents from Epic 3:**
1. **Ingestion Agent** (Story 1.2) - Document processing and chunking
2. **Clause Extraction Agent** (Story 3.1) - Extract clauses and detect red flags
3. **Risk Scoring Agent** (Story 3.2) - Assign risk scores to clauses
4. **Summary Agent** (Story 3.3) - Generate diligence memo
5. **Provenance Agent** (Story 3.4) - Track source information
6. **Checklist Agent** (Story 3.5) - Generate follow-up questions

**Agent Locations:**
- `backend/app/agents/ingestion.py`
- `backend/app/agents/clause_extraction.py`
- `backend/app/agents/risk_scoring.py`
- `backend/app/agents/summary.py`
- `backend/app/agents/provenance.py`
- `backend/app/agents/checklist.py`

**IMPORTANT - Agent Implementation Pattern:**
All agents from Epic 3 use `langgraph.prebuilt.create_react_agent()` for autonomous tool looping. This is the established pattern for this project.

**Reference Implementation:**
- See Story 3.1 (Clause Extraction Agent) Dev Notes for detailed implementation pattern
- See Story 3.2 (Risk Scoring Agent) Dev Notes for additional examples
- Key pattern: Agents use `create_react_agent()` which handles autonomous tool looping without manual orchestration

**Agent Architecture:**
```python
from langgraph.prebuilt import create_react_agent

# Each agent follows this pattern:
agent_executor = create_react_agent(
    model=llm,
    tools=[tool1, tool2, tool3],
    state_modifier="system prompt"
)

# Invoke with recursion limit
result = agent_executor.invoke(
    {"messages": [HumanMessage(content="task")]},
    config={"recursion_limit": 50}
)
```

### Orchestration Flow

**Standard Workflow:**
```
START
  ↓
Ingestion Agent (process document)
  ↓
Clause Extraction Agent (extract clauses, detect red flags)
  ↓
Risk Scoring Agent (score clauses)
  ↓
Summary Agent (generate memo)
  ↓
Provenance Agent (add source tracking)
  ↓
Checklist Agent (generate questions)
  ↓
END
```

**With Supervisor:**
```
START
  ↓
Supervisor (decide next step)
  ↓
Agent Node (execute task via create_react_agent)
  ↓
Supervisor (analyze results, decide next)
  ↓
... (repeat until complete)
  ↓
END
```

**Note on Agent Execution:**
Each agent node in the orchestration graph will invoke the agent's `create_react_agent` executor. The agents handle their own internal tool looping autonomously. The orchestrator's job is to:
1. Route to the correct agent based on workflow state
2. Pass the appropriate state/context to the agent
3. Collect the agent's results
4. Update the orchestration state
5. Decide the next agent to invoke

### State Management

**OrchestrationState Fields:**
[Source: PRD Epic 4 requirements]

```python
class OrchestrationState(TypedDict):
    # Document info
    document_id: str
    document_chunks: List[str]
    
    # Workflow tracking
    current_step: str
    completed_steps: List[str]
    
    # Agent outputs
    extracted_clauses: List[ExtractedClause]
    risk_scores: List[RiskScore]
    summary: str
    provenance_data: Dict
    checklist: List[ChecklistItem]
    
    # Error handling
    errors: List[str]
    retry_count: int
    
    # Metadata
    metadata: Dict
    started_at: str
    completed_at: Optional[str]
```

### LLM Configuration

**Model:** OpenAI GPT-4o-mini
**Tracing:** LangSmith enabled
**Framework:** LangGraph with StateGraph
[Source: architecture/3-tech-stack.md]

### Error Handling Strategy

**Error Types:**
1. **Agent Failure** - Individual agent throws exception
2. **Data Validation** - Invalid state transitions
3. **Timeout** - Agent takes too long
4. **Loop Detection** - Infinite loop in graph

**Recovery Strategies:**
1. **Retry with Backoff** - Retry failed agent up to 3 times
2. **Skip and Continue** - Mark agent as failed, continue workflow
3. **Graceful Degradation** - Return partial results
4. **Circuit Breaker** - Stop after repeated failures

### Loop Prevention

**Mechanisms:**
- Maximum iteration limit (50)
- Track visited nodes in state
- Detect cycles in execution path
- Timeout for overall orchestration (5 minutes)

### Visualization Requirements

**Graph Display:**
[Source: architecture/6-implementation-details.md#65]
- Reusable helper function for notebook display
- Show all nodes (agents + supervisor)
- Show edges with labels
- Highlight conditional paths
- Display current state during execution

**Two-Level Visualization:**
1. **Orchestration Graph** - Shows supervisor and agent nodes at high level
2. **Individual Agent Graphs** - Each agent has its own internal graph (from `create_react_agent`)

The orchestration visualization shows the workflow between agents, while each agent's internal graph (available via their `get_graph_visualization()` method) shows their tool usage patterns.

### Implementation References

**CRITICAL - Review These Stories First:**

Before implementing the orchestrator, developers should review:

1. **Story 3.1 - Clause Extraction Agent**
   - Section: "Dev Agent Record → Implementation Pattern for Future Agents"
   - Shows complete `create_react_agent` pattern
   - Documents tool description best practices
   - Explains recursion limits and stopping conditions
   - Performance characteristics (~10-15 messages, 30-45 seconds)

2. **Story 3.2 - Risk Scoring Agent**
   - Additional examples of `create_react_agent` usage
   - Shows how agents integrate with each other's outputs
   - Demonstrates state management patterns

**Key Takeaways from Story 3.1:**
- Use `langgraph.prebuilt.create_react_agent()` for all agents
- Tool descriptions must be explicit about input/output formats
- Include clear stopping conditions in prompts
- Set recursion_limit to 50 for complex tasks
- Agents loop autonomously - no manual orchestration needed within agent
- Parse results from messages with proper validation

**Integration Pattern:**
The orchestrator will invoke each agent's executor and collect results, but does NOT need to manage the agent's internal tool looping - that's handled by `create_react_agent`.

## Testing

**Test Location:** `backend/tests/test_orchestration.py`

**Test Coverage Requirements:**
- Orchestrator initialization
- State management and transitions
- Agent routing logic
- Supervisor decision-making
- Error handling and recovery
- Loop prevention
- Complete end-to-end workflow
- Graph visualization generation

**Testing Framework:** Pytest (per architecture/3-tech-stack.md)

**Mocking Strategy:**
- Mock individual agents to isolate orchestrator
- Mock LLM calls for supervisor reasoning
- Use small sample documents for integration tests
- Mock external services (Qdrant, etc.)

**Integration Test:**
- Use real document from `data/`
- Run complete orchestration
- Validate all agent outputs
- Verify state transitions
- Check final results structure

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-21 | 1.0 | Initial story creation for Epic 4 | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
Claude 3.5 Sonnet (via Cline)

### Debug Log References
None - All tests passed successfully on first run after fixes.

### Completion Notes List
- Implemented DocumentOrchestrator using LangGraph StateGraph for multi-agent coordination
- Created OrchestrationState TypedDict model with all required fields for workflow management
- Implemented supervisor-based routing pattern with deterministic workflow progression
- Created 6 agent node functions (ingestion, clause extraction, risk scoring, summary, provenance, checklist)
- Each node handles state updates, error logging, and metadata tracking
- Implemented comprehensive error handling with graceful degradation (continues workflow on errors)
- Added loop prevention with MAX_ITERATIONS=50 and error threshold (>3 errors stops workflow)
p- Implemented state initialization with auto-generated document IDs using MD5 hash
- Created run_orchestration() method that returns structured results with status tracking
- Added get_graph_visualization() method for LangGraph visualization support
- Created comprehensive test suite with 25 tests covering all functionality
- All tests passing (25/25) with proper mocking of agent dependencies
- Tests cover: initialization, state management, supervisor logic, agent nodes, error handling, visualization, and end-to-end workflow
- Fixed minor issues: graph visualization test approach, checklist import names
- All acceptance criteria met and validated through tests

### File List
**Created:**
- backend/app/models/orchestration.py - OrchestrationState and ChecklistItem TypedDict models
- backend/app/orchestration/__init__.py - Module initialization with DocumentOrchestrator export
- backend/app/orchestration/pipeline.py - Complete DocumentOrchestrator implementation (700+ lines)
- backend/tests/test_orchestration.py - Comprehensive test suite with 25 tests
- notebooks/E08_Orchestration_Demo.py - Jupytext demonstration notebook showing complete workflow

**Modified:**
- backend/app/agents/clause_extraction.py - Added lazy retriever initialization pattern
- backend/tests/test_clause_extraction.py - Updated tests to work with lazy retriever (16/16 passing)

**Key Implementation Details:**
- Uses LangGraph StateGraph with MemorySaver checkpointer for state persistence
- Supervisor node uses deterministic routing based on completed_steps tracking
- Each agent node wraps existing agent executors (from Epic 3) and manages state updates
- Error handling allows workflow to continue even if individual agents fail
- State includes comprehensive metadata tracking for each agent's execution
- Graph structure: Supervisor → Agent → Supervisor (repeat) → END
- Conditional edges route based on supervisor's next_agent decision
- All 7 acceptance criteria fully implemented and tested

## QA Results
_To be filled by QA Agent_
