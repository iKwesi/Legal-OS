{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33bdc24e",
   "metadata": {},
   "source": [
    "# Legal-OS: Complete M&A Document Analysis System\n",
    "\n",
    "This notebook demonstrates the entire Legal-OS pipeline in a single, cohesive workflow.\n",
    "It combines all Epic demonstrations (E01-E08) with shared resources and progressive complexity.\n",
    "\n",
    "## System Overview\n",
    "\n",
    "Legal-OS is an AI-powered M&A due diligence system featuring:\n",
    "- **Document Ingestion & RAG** - Process legal documents with vector search\n",
    "- **Clause Extraction** - Identify M&A clauses with LangGraph agents\n",
    "- **Risk Scoring** - Assess risks with rule-based heuristics\n",
    "- **Summary Generation** - Create comprehensive diligence memos\n",
    "- **Source Tracking** - Maintain provenance for all findings\n",
    "- **Checklist Generation** - Produce actionable follow-up items\n",
    "- **Orchestration** - Coordinate all agents in a unified workflow\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Setup & Configuration** - One-time environment setup\n",
    "2. **Document Ingestion** - Load and process M&A document (shared across all agents)\n",
    "3. **RAG Pipeline** - Test retrieval and question answering\n",
    "4. **Agent Demonstrations** - Sequential agent workflow\n",
    "5. **End-to-End Orchestration** - Complete automated pipeline\n",
    "6. **Results & Export** - Consolidated results and exports\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Environment variables configured (OPENAI_API_KEY)\n",
    "- Sample M&A documents in `data/` directory\n",
    "- Backend dependencies installed (`cd backend && uv sync`)\n",
    "\n",
    "## Note\n",
    "\n",
    "This notebook uses **in-memory Qdrant** - no Docker required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939772f",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Setup & Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8236827e",
   "metadata": {
    "title": "Setup and Imports"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LEGAL-OS: M&A DOCUMENT ANALYSIS SYSTEM\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Environment setup complete\n",
      "   OPENAI_API_KEY: ********************P2EA\n",
      "   Using in-memory Qdrant (no Docker required)\n",
      "   Backend path: /Users/rbblankson34/Documents/Projects/Legal_AI/Legal-OS/backend\n",
      "   HTTP logging: Suppressed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from uuid import uuid4\n",
    "from collections import defaultdict\n",
    "\n",
    "# Try to import IPython for visualization\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    IPYTHON_AVAILABLE = True\n",
    "except ImportError:\n",
    "    IPYTHON_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  IPython not available - visualization will be skipped\")\n",
    "\n",
    "# Add backend to Python path\n",
    "# Handle both script and notebook execution\n",
    "try:\n",
    "    backend_path = Path(__file__).parent.parent / \"backend\"\n",
    "except NameError:\n",
    "    # __file__ not defined in Jupyter notebooks\n",
    "    backend_path = Path.cwd() / \"backend\"\n",
    "    if not backend_path.exists():\n",
    "        backend_path = Path.cwd().parent / \"backend\"\n",
    "\n",
    "if backend_path.exists():\n",
    "    sys.path.insert(0, str(backend_path))\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Warning: Backend path not found. Tried: {backend_path}\")\n",
    "\n",
    "# Load environment variables\n",
    "env_path = backend_path / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "# Disable verbose HTTP logging\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"openai\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"cohere\").setLevel(logging.WARNING)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LEGAL-OS: M&A DOCUMENT ANALYSIS SYSTEM\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ Environment setup complete\")\n",
    "print(f\"   OPENAI_API_KEY: {'*' * 20}{os.getenv('OPENAI_API_KEY', '')[-4:]}\")\n",
    "print(f\"   Using in-memory Qdrant (no Docker required)\")\n",
    "print(f\"   Backend path: {backend_path}\")\n",
    "print(f\"   HTTP logging: Suppressed\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f91ed",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Document Ingestion (Shared Resource)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b46280",
   "metadata": {
    "title": "Document Ingestion"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOCUMENT INGESTION\n",
      "================================================================================\n",
      "\n",
      "üìÑ Document: Freedom_Final_Asset_Agreement.pdf\n",
      "   Size: 284.84 KB\n",
      "\n",
      "‚úÖ Ingestion Complete! (8.91s)\n",
      "   Document ID: 31da81a9-e221-43fa-a03b-03e86eefb42e\n",
      "   Total chunks: 345\n",
      "   This vector store will be reused across all agents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.pipelines.ingestion_pipeline import IngestionPipeline\n",
    "\n",
    "# Select the Freedom M&A document\n",
    "# Handle both script and notebook execution\n",
    "try:\n",
    "    data_dir = Path(__file__).parent.parent / \"data\"\n",
    "except NameError:\n",
    "    # __file__ not defined in Jupyter notebooks\n",
    "    data_dir = Path.cwd() / \"data\"\n",
    "    if not data_dir.exists():\n",
    "        data_dir = Path.cwd().parent / \"data\"\n",
    "\n",
    "freedom_doc = data_dir / \"Freedom_Final_Asset_Agreement.pdf\"\n",
    "\n",
    "if not freedom_doc.exists():\n",
    "    sample_docs = list(data_dir.glob(\"*.pdf\"))\n",
    "    if not sample_docs:\n",
    "        raise FileNotFoundError(f\"No PDF documents found in {data_dir}\")\n",
    "    sample_doc = sample_docs[0]\n",
    "    print(f\"‚ö†Ô∏è  Freedom document not found, using {sample_doc.name}\")\n",
    "else:\n",
    "    sample_doc = freedom_doc\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DOCUMENT INGESTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìÑ Document: {sample_doc.name}\")\n",
    "print(f\"   Size: {sample_doc.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# Create ingestion pipeline with in-memory vector store\n",
    "pipeline = IngestionPipeline(use_memory=True)\n",
    "session_id = str(uuid4())\n",
    "\n",
    "# Ingest document\n",
    "ingestion_start = time.time()\n",
    "result = pipeline.ingest_document(file_path=str(sample_doc), session_id=session_id)\n",
    "ingestion_time = time.time() - ingestion_start\n",
    "\n",
    "# Get shared resources\n",
    "vector_store = pipeline.vector_store\n",
    "document_id = result[\"document_id\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Ingestion Complete! ({ingestion_time:.2f}s)\")\n",
    "print(f\"   Document ID: {document_id}\")\n",
    "print(f\"   Total chunks: {result['chunk_count']}\")\n",
    "print(f\"   This vector store will be reused across all agents.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6c111",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: RAG Pipeline Test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4867d27",
   "metadata": {
    "title": "RAG Pipeline Test"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAG PIPELINE TEST\n",
      "================================================================================\n",
      "\n",
      "‚ùì Question: What are the key parties involved in this agreement?\n",
      "\n",
      "‚úÖ RAG Query Complete! (2.39s)\n",
      "\n",
      "üí° Answer:\n",
      "   The key parties involved in this agreement are the Buyer and the Seller. Additionally, their respective successors and permitted assigns are also mentioned as parties to the agreement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RAG PIPELINE TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_question = \"What are the key parties involved in this agreement?\"\n",
    "print(f\"\\n‚ùì Question: {test_question}\")\n",
    "\n",
    "# Create RAG chain\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\\n\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Execute query\n",
    "rag_start = time.time()\n",
    "response = rag_chain.invoke({\"input\": test_question})\n",
    "rag_time = time.time() - rag_start\n",
    "\n",
    "print(f\"\\n‚úÖ RAG Query Complete! ({rag_time:.2f}s)\")\n",
    "print(f\"\\nüí° Answer:\")\n",
    "print(f\"   {response.get('answer', '')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413f115",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3.5: LangSmith Setup (Optional)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd101225",
   "metadata": {
    "title": "LangSmith Setup"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LANGSMITH TRACING SETUP\n",
      "================================================================================\n",
      "\n",
      "‚úÖ LangSmith tracing enabled\n",
      "   API Key: ********************1de5\n",
      "   Project: Legal-OS-Evaluation\n",
      "   View traces at: https://smith.langchain.com/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LANGSMITH TRACING SETUP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for LangSmith API key\n",
    "langsmith_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "if langsmith_api_key:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"Legal-OS-Evaluation\"\n",
    "    print(\"\\n‚úÖ LangSmith tracing enabled\")\n",
    "    print(f\"   API Key: {'*' * 20}{langsmith_api_key[-4:]}\")\n",
    "    print(f\"   Project: Legal-OS-Evaluation\")\n",
    "    print(f\"   View traces at: https://smith.langchain.com/\")\n",
    "else:\n",
    "    print(\"\\n‚è≠Ô∏è  LangSmith tracing disabled\")\n",
    "    print(\"   To enable: Add LANGCHAIN_API_KEY to backend/.env\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f353fdd",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3.6: Comprehensive RAG Evaluation with RAGAS\n",
    "---\n",
    "\n",
    "This section evaluates 10 different retriever configurations:\n",
    "- 2 chunking strategies (Naive, Semantic)\n",
    "- 5 retrieval methods (Vector, BM25, Multi-Query, Ensemble, Cohere Rerank)\n",
    "\n",
    "**Note:** This evaluation takes 15-20 minutes to complete.\n",
    "Set RUN_EVALUATION = False to skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8515092e",
   "metadata": {
    "title": "Evaluation Configuration"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RAG EVALUATION WITH RAGAS\n",
      "================================================================================\n",
      "\n",
      "üìä Evaluation Configuration:\n",
      "   Run Evaluation: True\n",
      "   Cohere API Key: ‚úÖ Configured\n",
      "   Expected configurations: 10\n",
      "   Estimated time: 15 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RAG EVALUATION WITH RAGAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Toggle to enable/disable evaluation\n",
    "RUN_EVALUATION = True  # Set to False to skip evaluation\n",
    "\n",
    "# Check for Cohere API key\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "has_cohere = cohere_api_key is not None\n",
    "\n",
    "print(f\"\\nüìä Evaluation Configuration:\")\n",
    "print(f\"   Run Evaluation: {RUN_EVALUATION}\")\n",
    "print(f\"   Cohere API Key: {'‚úÖ Configured' if has_cohere else '‚ùå Not configured (will skip reranking)'}\")\n",
    "print(f\"   Expected configurations: {10 if has_cohere else 8}\")\n",
    "print(f\"   Estimated time: {15 if has_cohere else 12} minutes\\n\")\n",
    "\n",
    "if not RUN_EVALUATION:\n",
    "    print(\"‚è≠Ô∏è  Skipping RAG evaluation (RUN_EVALUATION=False)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b412e3f7",
   "metadata": {
    "title": "Run Evaluations"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rbblankson34/Documents/Projects/Legal_AI/Legal-OS/backend/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing evaluator...\n",
      "‚úÖ Evaluator initialized\n",
      "\n",
      "üöÄ Running 10 configurations...\n",
      "\n",
      "[1/10] Evaluating: Naive + Vector Similarity\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  12%|‚ñà‚ñé        | 5/40 [00:08<00:49,  1.42s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  25%|‚ñà‚ñà‚ñå       | 10/40 [00:16<00:47,  1.57s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:19<00:19,  1.22it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:24<00:27,  1.30s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:34<00:27,  1.84s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:48<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 84.06s\n",
      "   Metrics: Precision=0.6040, Recall=0.1350, Faithfulness=0.8747, Relevancy=0.2868\n",
      "\n",
      "[2/10] Evaluating: Naive + BM25 Keyword\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|‚ñà‚ñà        | 8/40 [00:07<00:19,  1.62it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:14<00:13,  1.66it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [00:16<00:18,  1.22it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [00:20<00:16,  1.09it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:45<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 67.75s\n",
      "   Metrics: Precision=0.5555, Recall=0.2100, Faithfulness=0.9187, Relevancy=0.1839\n",
      "\n",
      "[3/10] Evaluating: Naive + Multi-Query\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  12%|‚ñà‚ñé        | 5/40 [00:07<00:43,  1.24s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:13<00:13,  1.81it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:15<00:15,  1.45it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:19<00:16,  1.17it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:56<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 117.35s\n",
      "   Metrics: Precision=0.5755, Recall=0.2183, Faithfulness=0.8671, Relevancy=0.2887\n",
      "\n",
      "[4/10] Evaluating: Naive + Ensemble (Vector+BM25+MultiQuery)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  12%|‚ñà‚ñé        | 5/40 [00:07<00:44,  1.28s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:15<00:17,  1.35it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [01:23<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 147.44s\n",
      "   Metrics: Precision=0.6321, Recall=0.2517, Faithfulness=0.8656, Relevancy=0.3779\n",
      "\n",
      "[5/10] Evaluating: Naive + Cohere Reranking\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|‚ñà‚ñà        | 8/40 [00:07<00:21,  1.49it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:16<00:20,  1.11it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:26<00:21,  1.34s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:44<00:00,  1.11s/it]\n",
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 79.77s\n",
      "   Metrics: Precision=0.6677, Recall=0.2183, Faithfulness=0.7722, Relevancy=0.2870\n",
      "\n",
      "[6/10] Evaluating: Semantic + Vector Similarity\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  15%|‚ñà‚ñå        | 6/40 [00:07<00:34,  1.02s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:45<00:00,  1.13s/it]\n",
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 76.26s\n",
      "   Metrics: Precision=0.6223, Recall=0.1100, Faithfulness=0.7912, Relevancy=0.2887\n",
      "\n",
      "[7/10] Evaluating: Semantic + BM25 Keyword\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:08<00:17,  1.77it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  25%|‚ñà‚ñà‚ñå       | 10/40 [00:09<00:21,  1.37it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:14<00:12,  1.87it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:20<00:18,  1.05it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:24<00:19,  1.21s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:43<00:00,  1.10s/it]\n",
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 67.03s\n",
      "   Metrics: Precision=0.5535, Recall=0.1600, Faithfulness=0.9125, Relevancy=0.1894\n",
      "\n",
      "[8/10] Evaluating: Semantic + Multi-Query\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:08<00:22,  1.39it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:20<00:23,  1.19s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:54<00:00,  1.37s/it]\n",
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 106.33s\n",
      "   Metrics: Precision=0.5860, Recall=0.1433, Faithfulness=0.8536, Relevancy=0.2868\n",
      "\n",
      "[9/10] Evaluating: Semantic + Ensemble (Vector+BM25+MultiQuery)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:14<00:14,  1.70it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [01:16<00:00,  1.92s/it]\n",
      "SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 136.89s\n",
      "   Metrics: Precision=0.5457, Recall=0.3267, Faithfulness=0.9474, Relevancy=0.3771\n",
      "\n",
      "[10/10] Evaluating: Semantic + Cohere Reranking\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|‚ñà‚ñà        | 8/40 [00:08<00:22,  1.40it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:10<00:31,  1.01s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:15<00:15,  1.58it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:48<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete in 85.28s\n",
      "   Metrics: Precision=0.6308, Recall=0.2600, Faithfulness=0.8144, Relevancy=0.3795\n",
      "\n",
      "‚úÖ All 10 evaluations complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION:\n",
    "    from app.rag.evaluation_langchain import LangChainRAGEvaluator\n",
    "    from app.core.config import settings\n",
    "    \n",
    "    print(\"üîß Initializing evaluator...\")\n",
    "    # Use absolute path for SGD\n",
    "    sgd_path = backend_path / \"golden_dataset\" / \"sgd_benchmark.csv\"\n",
    "    evaluator = LangChainRAGEvaluator(sgd_path=str(sgd_path))\n",
    "    print(\"‚úÖ Evaluator initialized\\n\")\n",
    "    \n",
    "    # Store all results\n",
    "    all_results = []\n",
    "    \n",
    "    # Configuration matrix\n",
    "    chunking_strategies = [\n",
    "        (\"naive\", {\"chunk_size\": settings.chunk_size, \"chunk_overlap\": settings.chunk_overlap}),\n",
    "        (\"semantic\", {\"breakpoint_threshold_type\": \"percentile\", \"breakpoint_threshold_amount\": 95.0}),\n",
    "    ]\n",
    "    \n",
    "    retriever_configs = [\n",
    "        (\"Vector Similarity\", \"evaluate_naive_retrieval\", {}),\n",
    "        (\"BM25 Keyword\", \"evaluate_bm25_retrieval\", {}),\n",
    "        (\"Multi-Query\", \"evaluate_multiquery_retrieval\", {}),\n",
    "        (\"Ensemble (Vector+BM25+MultiQuery)\", \"evaluate_ensemble_retrieval\", {}),\n",
    "    ]\n",
    "    \n",
    "    # Add Cohere reranking if API key available\n",
    "    if has_cohere:\n",
    "        retriever_configs.append(\n",
    "            (\"Cohere Reranking\", \"evaluate_contextual_compression_retrieval\", {\"cohere_api_key\": cohere_api_key})\n",
    "        )\n",
    "    \n",
    "    total_configs = len(chunking_strategies) * len(retriever_configs)\n",
    "    current_config = 0\n",
    "    \n",
    "    print(f\"üöÄ Running {total_configs} configurations...\\n\")\n",
    "    \n",
    "    # Run all combinations\n",
    "    for chunking_name, chunking_params in chunking_strategies:\n",
    "        for retriever_name, method_name, extra_params in retriever_configs:\n",
    "            current_config += 1\n",
    "            config_name = f\"{chunking_name.title()} + {retriever_name}\"\n",
    "            \n",
    "            print(f\"[{current_config}/{total_configs}] Evaluating: {config_name}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            try:\n",
    "                # Get the evaluation method\n",
    "                eval_method = getattr(evaluator, method_name)\n",
    "                \n",
    "                # Run evaluation\n",
    "                result = eval_method(\n",
    "                    chunking_strategy=chunking_name,\n",
    "                    chunking_params=chunking_params,\n",
    "                    top_k=10,\n",
    "                    **extra_params\n",
    "                )\n",
    "                \n",
    "                # Add configuration name\n",
    "                result[\"configuration\"] = config_name\n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"‚úÖ Complete in {result['execution_time_seconds']:.2f}s\")\n",
    "                print(f\"   Metrics: Precision={result['metrics']['context_precision']:.4f}, \"\n",
    "                      f\"Recall={result['metrics']['context_recall']:.4f}, \"\n",
    "                      f\"Faithfulness={result['metrics']['faithfulness']:.4f}, \"\n",
    "                      f\"Relevancy={result['metrics']['answer_relevancy']:.4f}\")\n",
    "                print()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed: {str(e)}\")\n",
    "                print()\n",
    "    \n",
    "    print(f\"‚úÖ All {len(all_results)} evaluations complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512dace",
   "metadata": {},
   "source": [
    "## Evaluation Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78073b7c",
   "metadata": {
    "title": "Results Comparison"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "üìä RANKED RETRIEVER COMPARISON (BEST TO WORST)\n",
      "============================================================================================================================================\n",
      "\n",
      "Rank                                Configuration Chunking                     Retriever  k Precision Recall Faithfulness Relevancy Time (s) Average\n",
      " ü•á 1 Semantic + Ensemble (Vector+BM25+MultiQuery) semantic                      ensemble 10     54.6%  32.7%        94.7%     37.7%  136.89s   54.9%\n",
      " ü•à 2    Naive + Ensemble (Vector+BM25+MultiQuery)    naive                      ensemble 10     63.2%  25.2%        86.6%     37.8%  147.44s   53.2%\n",
      " ü•â 3                  Semantic + Cohere Reranking semantic contextual_compression_cohere 10     63.1%  26.0%        81.4%     38.0%   85.28s   52.1%\n",
      "   4                          Naive + Multi-Query    naive                    multiquery 10     57.6%  21.8%        86.7%     28.9%  117.35s   48.7%\n",
      "   5                     Naive + Cohere Reranking    naive contextual_compression_cohere 10     66.8%  21.8%        77.2%     28.7%   79.77s   48.6%\n",
      "   6                    Naive + Vector Similarity    naive                         naive 10     60.4%  13.5%        87.5%     28.7%   84.06s   47.5%\n",
      "   7                       Semantic + Multi-Query semantic                    multiquery 10     58.6%  14.3%        85.4%     28.7%  106.33s   46.7%\n",
      "   8                         Naive + BM25 Keyword    naive                          bm25 10     55.5%  21.0%        91.9%     18.4%   67.75s   46.7%\n",
      "   9                      Semantic + BM25 Keyword semantic                          bm25 10     55.4%  16.0%        91.2%     18.9%   67.03s   45.4%\n",
      "  10                 Semantic + Vector Similarity semantic                         naive 10     62.2%  11.0%        79.1%     28.9%   76.26s   45.3%\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "DETAILED RESULTS BY CONFIGURATION\n",
      "========================================================================================================================\n",
      "\n",
      "[1] Naive + Vector Similarity\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Naive\n",
      "   Retriever: naive\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.6040\n",
      "      Context Recall:     0.1350\n",
      "      Faithfulness:       0.8747\n",
      "      Answer Relevancy:   0.2868\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 84.06s\n",
      "\n",
      "[2] Naive + BM25 Keyword\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Naive\n",
      "   Retriever: bm25\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.5555\n",
      "      Context Recall:     0.2100\n",
      "      Faithfulness:       0.9187\n",
      "      Answer Relevancy:   0.1839\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 67.75s\n",
      "\n",
      "[3] Naive + Multi-Query\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Naive\n",
      "   Retriever: multiquery\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.5755\n",
      "      Context Recall:     0.2183\n",
      "      Faithfulness:       0.8671\n",
      "      Answer Relevancy:   0.2887\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 117.35s\n",
      "\n",
      "[4] Naive + Ensemble (Vector+BM25+MultiQuery)\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Naive\n",
      "   Retriever: ensemble\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.6321\n",
      "      Context Recall:     0.2517\n",
      "      Faithfulness:       0.8656\n",
      "      Answer Relevancy:   0.3779\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 147.44s\n",
      "\n",
      "[5] Naive + Cohere Reranking\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Naive\n",
      "   Retriever: contextual_compression_cohere\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.6677\n",
      "      Context Recall:     0.2183\n",
      "      Faithfulness:       0.7722\n",
      "      Answer Relevancy:   0.2870\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 79.77s\n",
      "\n",
      "[6] Semantic + Vector Similarity\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Semantic\n",
      "   Retriever: naive\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.6223\n",
      "      Context Recall:     0.1100\n",
      "      Faithfulness:       0.7912\n",
      "      Answer Relevancy:   0.2887\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 76.26s\n",
      "\n",
      "[7] Semantic + BM25 Keyword\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Semantic\n",
      "   Retriever: bm25\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.5535\n",
      "      Context Recall:     0.1600\n",
      "      Faithfulness:       0.9125\n",
      "      Answer Relevancy:   0.1894\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 67.03s\n",
      "\n",
      "[8] Semantic + Multi-Query\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Semantic\n",
      "   Retriever: multiquery\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.5860\n",
      "      Context Recall:     0.1433\n",
      "      Faithfulness:       0.8536\n",
      "      Answer Relevancy:   0.2868\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 106.33s\n",
      "\n",
      "[9] Semantic + Ensemble (Vector+BM25+MultiQuery)\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Semantic\n",
      "   Retriever: ensemble\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.5457\n",
      "      Context Recall:     0.3267\n",
      "      Faithfulness:       0.9474\n",
      "      Answer Relevancy:   0.3771\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 136.89s\n",
      "\n",
      "[10] Semantic + Cohere Reranking\n",
      "--------------------------------------------------------------------------------\n",
      "   Chunking: Semantic\n",
      "   Retriever: contextual_compression_cohere\n",
      "   Top-K: 10\n",
      "   Documents: 345\n",
      "   Samples: 10\n",
      "\n",
      "   üìä RAGAS Metrics:\n",
      "      Context Precision:  0.6308\n",
      "      Context Recall:     0.2600\n",
      "      Faithfulness:       0.8144\n",
      "      Answer Relevancy:   0.3795\n",
      "\n",
      "   ‚è±Ô∏è  Execution Time: 85.28s\n",
      "\n",
      "========================================================================================================================\n",
      "RANKINGS BY METRIC\n",
      "========================================================================================================================\n",
      "\n",
      "üèÜ Best Precision:\n",
      "   5. Naive + Cohere Reranking                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.6677\n",
      "   2. Naive + Ensemble (Vector+BM25+MultiQuery)     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.6321\n",
      "   3. Semantic + Cohere Reranking                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.6308\n",
      "   10. Semantic + Vector Similarity                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.6223\n",
      "   6. Naive + Vector Similarity                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.6040\n",
      "\n",
      "üèÜ Best Recall:\n",
      "   1. Semantic + Ensemble (Vector+BM25+MultiQuery)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.3267\n",
      "   3. Semantic + Cohere Reranking                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2600\n",
      "   2. Naive + Ensemble (Vector+BM25+MultiQuery)     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2517\n",
      "   4. Naive + Multi-Query                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2183\n",
      "   5. Naive + Cohere Reranking                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2183\n",
      "\n",
      "üèÜ Best Faithfulness:\n",
      "   1. Semantic + Ensemble (Vector+BM25+MultiQuery)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë 0.9474\n",
      "   8. Naive + BM25 Keyword                          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.9187\n",
      "   9. Semantic + BM25 Keyword                       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 0.9125\n",
      "   6. Naive + Vector Similarity                     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.8747\n",
      "   4. Naive + Multi-Query                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.8671\n",
      "\n",
      "üèÜ Best Relevancy:\n",
      "   3. Semantic + Cohere Reranking                   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.3795\n",
      "   2. Naive + Ensemble (Vector+BM25+MultiQuery)     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.3779\n",
      "   1. Semantic + Ensemble (Vector+BM25+MultiQuery)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.3771\n",
      "   10. Semantic + Vector Similarity                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2887\n",
      "   4. Naive + Multi-Query                           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0.2887\n",
      "\n",
      "========================================================================================================================\n",
      "üèÜ BEST OVERALL RETRIEVER (BY AVERAGE SCORE)\n",
      "========================================================================================================================\n",
      "\n",
      "Configuration: Semantic + Ensemble (Vector+BM25+MultiQuery)\n",
      "   Context Precision:  0.5457\n",
      "   Context Recall:     0.3267\n",
      "   Faithfulness:       0.9474\n",
      "   Answer Relevancy:   0.3771\n",
      "   Average Score:      0.5492\n",
      "   Execution Time:     136.89s\n",
      "\n",
      "‚ö° FASTEST RETRIEVER\n",
      "   Configuration: Semantic + BM25 Keyword\n",
      "   Time: 67.03s\n",
      "   Average Score: 0.4538\n",
      "\n",
      "========================================================================================================================\n",
      "PERFORMANCE VS ACCURACY ANALYSIS\n",
      "========================================================================================================================\n",
      "\n",
      "Top 3 by Accuracy:\n",
      "   1. Semantic + Ensemble (Vector+BM25+MultiQuery)  Avg=0.5492, Time=136.89s\n",
      "   2. Naive + Ensemble (Vector+BM25+MultiQuery)     Avg=0.5318, Time=147.44s\n",
      "   3. Semantic + Cohere Reranking                   Avg=0.5212, Time= 85.28s\n",
      "\n",
      "Top 3 by Speed:\n",
      "   9. Semantic + BM25 Keyword                       Time= 67.03s, Avg=0.4538\n",
      "   8. Naive + BM25 Keyword                          Time= 67.75s, Avg=0.4670\n",
      "   10. Semantic + Vector Similarity                  Time= 76.26s, Avg=0.4530\n",
      "\n",
      "========================================================================================================================\n",
      "üí° RECOMMENDATION\n",
      "========================================================================================================================\n",
      "\n",
      "üéØ Recommended Retriever: Semantic + Ensemble (Vector+BM25+MultiQuery)\n",
      "\n",
      "   Why this retriever:\n",
      "   ‚úÖ Highest average score (0.5492)\n",
      "   ‚úÖ Best context precision (0.5457)\n",
      "   ‚úÖ Best faithfulness (0.9474)\n",
      "\n",
      "   ‚ö†Ô∏è  Note: This is not the fastest retriever\n",
      "   ‚ö° Fastest option: Semantic + BM25 Keyword (67.03s)\n",
      "      But with lower accuracy (Avg=0.4538)\n",
      "\n",
      "   üéØ Best Balance (Score/Speed): Naive + BM25 Keyword\n",
      "      Score: 0.4670, Time: 67.75s\n",
      "\n",
      "üíæ Evaluation results saved:\n",
      "   - ragas_evaluation_results.json (JSON - detailed results)\n",
      "   - ragas_evaluation_results.csv (CSV - comparison table)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION and all_results:\n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame([\n",
    "        {\n",
    "            \"Configuration\": r[\"configuration\"],\n",
    "            \"Chunking\": r[\"chunking_strategy\"],\n",
    "            \"Retriever\": r[\"retriever_type\"],\n",
    "            \"k\": r[\"top_k\"],\n",
    "            \"Precision\": r[\"metrics\"][\"context_precision\"],\n",
    "            \"Recall\": r[\"metrics\"][\"context_recall\"],\n",
    "            \"Faithfulness\": r[\"metrics\"][\"faithfulness\"],\n",
    "            \"Relevancy\": r[\"metrics\"][\"answer_relevancy\"],\n",
    "            \"Time (s)\": r[\"execution_time_seconds\"],\n",
    "        }\n",
    "        for r in all_results\n",
    "    ])\n",
    "    \n",
    "    # Calculate average score\n",
    "    comparison_df[\"Average\"] = comparison_df[[\"Precision\", \"Recall\", \"Faithfulness\", \"Relevancy\"]].mean(axis=1)\n",
    "    \n",
    "    # Sort by average score (best to worst)\n",
    "    comparison_df = comparison_df.sort_values(\"Average\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Add rank with medals\n",
    "    medals = ['ü•á', 'ü•à', 'ü•â'] + [''] * (len(comparison_df) - 3)\n",
    "    comparison_df.insert(0, 'Rank', [f\"{medal} {i+1}\".strip() for i, medal in enumerate(medals)])\n",
    "    \n",
    "    # Format for display\n",
    "    display_df = comparison_df.copy()\n",
    "    for col in ['Precision', 'Recall', 'Faithfulness', 'Relevancy', 'Average']:\n",
    "        display_df[col] = (display_df[col] * 100).round(1).astype(str) + '%'\n",
    "    display_df['Time (s)'] = display_df['Time (s)'].round(2).astype(str) + 's'\n",
    "    \n",
    "    print(\"=\" * 140)\n",
    "    print(\"üìä RANKED RETRIEVER COMPARISON (BEST TO WORST)\")\n",
    "    print(\"=\" * 140)\n",
    "    print()\n",
    "    print(display_df.to_string(index=False))\n",
    "    print()\n",
    "    \n",
    "    # Detailed results for each configuration\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(\"DETAILED RESULTS BY CONFIGURATION\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for i, result in enumerate(all_results, 1):\n",
    "        print(f\"\\n[{i}] {result['configuration']}\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"   Chunking: {result['chunking_strategy'].title()}\")\n",
    "        print(f\"   Retriever: {result['retriever_type']}\")\n",
    "        print(f\"   Top-K: {result['top_k']}\")\n",
    "        print(f\"   Documents: {result['num_documents']}\")\n",
    "        print(f\"   Samples: {result['num_samples']}\")\n",
    "        print(f\"\\n   üìä RAGAS Metrics:\")\n",
    "        print(f\"      Context Precision:  {result['metrics']['context_precision']:.4f}\")\n",
    "        print(f\"      Context Recall:     {result['metrics']['context_recall']:.4f}\")\n",
    "        print(f\"      Faithfulness:       {result['metrics']['faithfulness']:.4f}\")\n",
    "        print(f\"      Answer Relevancy:   {result['metrics']['answer_relevancy']:.4f}\")\n",
    "        print(f\"\\n   ‚è±Ô∏è  Execution Time: {result['execution_time_seconds']:.2f}s\")\n",
    "    \n",
    "    # Rankings by metric\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(\"RANKINGS BY METRIC\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    for metric in [\"Precision\", \"Recall\", \"Faithfulness\", \"Relevancy\"]:\n",
    "        ranked = comparison_df.sort_values(metric, ascending=False)\n",
    "        print(f\"\\nüèÜ Best {metric}:\")\n",
    "        for idx, row in ranked.head(5).iterrows():\n",
    "            bar_length = int(row[metric] * 50)  # Scale to 50 chars\n",
    "            bar = \"‚ñà\" * bar_length + \"‚ñë\" * (50 - bar_length)\n",
    "            print(f\"   {idx + 1}. {row['Configuration']:45s} {bar} {row[metric]:.4f}\")\n",
    "    \n",
    "    # Overall best (by average of all metrics)\n",
    "    comparison_df[\"Average\"] = comparison_df[[\"Precision\", \"Recall\", \"Faithfulness\", \"Relevancy\"]].mean(axis=1)\n",
    "    best_overall = comparison_df.loc[comparison_df[\"Average\"].idxmax()]\n",
    "    fastest = comparison_df.loc[comparison_df[\"Time (s)\"].idxmin()]\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 120)\n",
    "    print(\"üèÜ BEST OVERALL RETRIEVER (BY AVERAGE SCORE)\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"\\nConfiguration: {best_overall['Configuration']}\")\n",
    "    print(f\"   Context Precision:  {best_overall['Precision']:.4f}\")\n",
    "    print(f\"   Context Recall:     {best_overall['Recall']:.4f}\")\n",
    "    print(f\"   Faithfulness:       {best_overall['Faithfulness']:.4f}\")\n",
    "    print(f\"   Answer Relevancy:   {best_overall['Relevancy']:.4f}\")\n",
    "    print(f\"   Average Score:      {best_overall['Average']:.4f}\")\n",
    "    print(f\"   Execution Time:     {best_overall['Time (s)']:.2f}s\")\n",
    "    \n",
    "    print(f\"\\n‚ö° FASTEST RETRIEVER\")\n",
    "    print(f\"   Configuration: {fastest['Configuration']}\")\n",
    "    print(f\"   Time: {fastest['Time (s)']:.2f}s\")\n",
    "    print(f\"   Average Score: {fastest['Average']:.4f}\")\n",
    "    \n",
    "    # Performance vs Accuracy Analysis\n",
    "    print(f\"\\n\" + \"=\" * 120)\n",
    "    print(\"PERFORMANCE VS ACCURACY ANALYSIS\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # Sort by average score\n",
    "    sorted_by_score = comparison_df.sort_values(\"Average\", ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 3 by Accuracy:\")\n",
    "    for idx, row in sorted_by_score.head(3).iterrows():\n",
    "        print(f\"   {idx + 1}. {row['Configuration']:45s} Avg={row['Average']:.4f}, Time={row['Time (s)']:6.2f}s\")\n",
    "    \n",
    "    print(f\"\\nTop 3 by Speed:\")\n",
    "    sorted_by_speed = comparison_df.sort_values(\"Time (s)\")\n",
    "    for idx, row in sorted_by_speed.head(3).iterrows():\n",
    "        print(f\"   {idx + 1}. {row['Configuration']:45s} Time={row['Time (s)']:6.2f}s, Avg={row['Average']:.4f}\")\n",
    "    \n",
    "    # Recommendation\n",
    "    print(f\"\\n\" + \"=\" * 120)\n",
    "    print(\"üí° RECOMMENDATION\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # Find best balance (high score, reasonable time)\n",
    "    comparison_df[\"Score_per_Second\"] = comparison_df[\"Average\"] / comparison_df[\"Time (s)\"]\n",
    "    best_balance = comparison_df.loc[comparison_df[\"Score_per_Second\"].idxmax()]\n",
    "    \n",
    "    print(f\"\\nüéØ Recommended Retriever: {best_overall['Configuration']}\")\n",
    "    print(f\"\\n   Why this retriever:\")\n",
    "    print(f\"   ‚úÖ Highest average score ({best_overall['Average']:.4f})\")\n",
    "    print(f\"   ‚úÖ Best context precision ({best_overall['Precision']:.4f})\")\n",
    "    print(f\"   ‚úÖ Best faithfulness ({best_overall['Faithfulness']:.4f})\")\n",
    "    \n",
    "    if best_overall['Configuration'] != fastest['Configuration']:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Note: This is not the fastest retriever\")\n",
    "        print(f\"   ‚ö° Fastest option: {fastest['Configuration']} ({fastest['Time (s)']:.2f}s)\")\n",
    "        print(f\"      But with lower accuracy (Avg={fastest['Average']:.4f})\")\n",
    "    \n",
    "    print(f\"\\n   üéØ Best Balance (Score/Speed): {best_balance['Configuration']}\")\n",
    "    print(f\"      Score: {best_balance['Average']:.4f}, Time: {best_balance['Time (s)']:.2f}s\")\n",
    "    \n",
    "    # Export evaluation results\n",
    "    eval_results_path = backend_path / \"ragas_evaluation_results.json\"\n",
    "    with open(eval_results_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=2, default=str)\n",
    "    \n",
    "    eval_csv_path = backend_path / \"ragas_evaluation_results.csv\"\n",
    "    comparison_df.to_csv(eval_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Evaluation results saved:\")\n",
    "    print(f\"   - {eval_results_path.name} (JSON - detailed results)\")\n",
    "    print(f\"   - {eval_csv_path.name} (CSV - comparison table)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ef42e",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Agent Demonstrations (Sequential Workflow)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37da573",
   "metadata": {},
   "source": [
    "## 4.1: Clause Extraction Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0eb423",
   "metadata": {
    "title": "Clause Extraction Agent"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CLAUSE EXTRACTION AGENT\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Agent initialized (Model: gpt-4o-mini, Tools: 3)\n",
      "\n",
      "üìä Agent Workflow Graph:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Extracting clauses...\n",
      "‚úÖ Found clause: Payment Terms\n",
      "‚úÖ Found clause: Indemnification\n",
      "‚úÖ Found clause: Warranties\n",
      "‚úÖ Found red flag: High\n",
      "‚úÖ Found red flag: Medium\n",
      "‚úÖ Found red flag: Critical\n",
      "‚úÖ Found red flag: High\n",
      "‚úÖ Found red flag: Medium\n",
      "\n",
      "‚úÖ Complete! (37.74s)\n",
      "   Clauses: 3, Red Flags: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.agents.clause_extraction import ClauseExtractionAgent\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLAUSE EXTRACTION AGENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "clause_agent = ClauseExtractionAgent(\n",
    "    vector_store=vector_store,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "print(f\"\\nü§ñ Agent initialized (Model: gpt-4o-mini, Tools: {len(clause_agent.tools)})\")\n",
    "\n",
    "# Visualize agent graph\n",
    "try:\n",
    "    graph_viz = clause_agent.get_graph_visualization()\n",
    "    if graph_viz and IPYTHON_AVAILABLE:\n",
    "        print(\"\\nüìä Agent Workflow Graph:\")\n",
    "        display(graph_viz)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Graph visualization not available: {e}\")\n",
    "\n",
    "print(f\"\\nüîç Extracting clauses...\")\n",
    "clause_start = time.time()\n",
    "clause_result = clause_agent.extract_clauses(document_id=document_id)\n",
    "clause_time = time.time() - clause_start\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! ({clause_time:.2f}s)\")\n",
    "print(f\"   Clauses: {len(clause_result.clauses)}, Red Flags: {len(clause_result.red_flags)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5949ab",
   "metadata": {},
   "source": [
    "## 4.2: Risk Scoring Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1bad4f",
   "metadata": {
    "title": "Risk Scoring Agent"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RISK SCORING AGENT\n",
      "================================================================================\n",
      "\n",
      "üìä Agent Workflow Graph:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Scoring risks...\n",
      "\n",
      "‚úÖ Complete! (27.41s)\n",
      "   Overall Risk: 65/100 (High)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.agents.risk_scoring import RiskScoringAgent\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RISK SCORING AGENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "risk_agent = RiskScoringAgent()\n",
    "\n",
    "try:\n",
    "    graph_viz = risk_agent.get_graph_visualization()\n",
    "    if graph_viz and IPYTHON_AVAILABLE:\n",
    "        print(\"\\nüìä Agent Workflow Graph:\")\n",
    "        display(graph_viz)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Graph visualization not available: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Scoring risks...\")\n",
    "risk_start = time.time()\n",
    "risk_result = risk_agent.score_risks(\n",
    "    clause_extraction_result=clause_result,\n",
    "    document_id=document_id\n",
    ")\n",
    "\n",
    "risk_time = time.time() - risk_start\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! ({risk_time:.2f}s)\")\n",
    "print(f\"   Overall Risk: {risk_result.overall_risk_score}/100 ({risk_result.overall_risk_category})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74ff28",
   "metadata": {},
   "source": [
    "## 4.3: Summary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16bc026e",
   "metadata": {
    "title": "Source Tracker"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.utils.source_tracker:SourceTracker initialized for document_id=31da81a9-e221-43fa-a03b-03e86eefb42e\n",
      "INFO:app.rag.vector_store:Creating retriever with search_kwargs: {'k': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOURCE TRACKER\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Created 3 source references\n",
      "üîó Generated 3 frontend links\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.utils.source_tracker import SourceTracker\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SOURCE TRACKER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tracker = SourceTracker(document_id=document_id)\n",
    "sample_chunks = vector_store.as_retriever(search_kwargs={\"k\": 3}).invoke(\"payment terms\")\n",
    "\n",
    "source_refs = []\n",
    "for i, chunk in enumerate(sample_chunks[:3], 1):\n",
    "    page = chunk.metadata.get(\"page\") if hasattr(chunk, 'metadata') else None\n",
    "    source_ref = tracker.create_source_reference(\n",
    "        chunk_id=f\"chunk_{i}\",\n",
    "        text_snippet=chunk.page_content[:150],\n",
    "        page=page,\n",
    "        confidence=0.95\n",
    "    )\n",
    "    source_refs.append(source_ref)\n",
    "\n",
    "source_metadata = tracker.create_source_metadata(\n",
    "    sources=source_refs,\n",
    "    extraction_method=\"llm_extraction\"\n",
    ")\n",
    "\n",
    "links = tracker.generate_links(source_metadata)\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(source_refs)} source references\")\n",
    "print(f\"üîó Generated {len(links)} frontend links\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9120567",
   "metadata": {},
   "source": [
    "## 4.5: Checklist Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1489048c",
   "metadata": {
    "title": "Checklist Agent"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.agents.checklist:ChecklistAgent initialized with model: gpt-4o-mini\n",
      "INFO:app.agents.checklist:Starting checklist generation\n",
      "INFO:app.agents.checklist:Invoking ReAct agent for checklist generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CHECKLIST AGENT\n",
      "================================================================================\n",
      "\n",
      "üìã Generating checklist...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Legal\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Financial\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Operational\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Risk Management\n",
      "INFO:app.agents.checklist:Generated 6 risk-based checklist items\n",
      "INFO:app.agents.checklist:Generated 2 follow-up questions\n",
      "INFO:app.agents.checklist:Parsed 26 checklist items and 2 questions from agent messages\n",
      "INFO:app.agents.checklist:Checklist generation complete: 26 items, 2 questions in 26.50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Complete! (26.50s)\n",
      "   Items: 26, Questions: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.agents.checklist import ChecklistAgent\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHECKLIST AGENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "checklist_agent = ChecklistAgent(model_name=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "print(f\"\\nüìã Generating checklist...\")\n",
    "checklist_start = time.time()\n",
    "checklist_result = checklist_agent.generate_checklist(memo)\n",
    "checklist_time = time.time() - checklist_start\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! ({checklist_time:.2f}s)\")\n",
    "print(f\"   Items: {len(checklist_result.checklist_items)}, Questions: {len(checklist_result.follow_up_questions)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09695331",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: End-to-End Orchestration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9693c48a",
   "metadata": {
    "title": "Orchestration"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.rag.vector_store:Initializing in-memory Qdrant client\n",
      "WARNING:app.rag.chunking:SemanticChunker from langchain_experimental not available. Using sentence-based fallback implementation.\n",
      "INFO:app.rag.chunking:Initialized SemanticChunker (using_langchain=False) with threshold_type=percentile, threshold_amount=95.0, embedding_model=text-embedding-3-small\n",
      "INFO:app.pipelines.ingestion_pipeline:IngestionPipeline initialized with shared vector store\n",
      "INFO:app.agents.clause_extraction:ClauseExtractionAgent initialized with create_react_agent (lazy retriever)\n",
      "INFO:app.agents.risk_scoring:RiskScoringAgent initialized with create_react_agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "END-TO-END ORCHESTRATION\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.agents.summary:SummaryAgent initialized with create_react_agent\n",
      "INFO:app.agents.checklist:ChecklistAgent initialized with model: gpt-4o-mini\n",
      "INFO:app.orchestration.pipeline:DocumentOrchestrator initialized with model=gpt-4o-mini\n",
      "INFO:app.orchestration.pipeline:Starting orchestration for document: /Users/rbblankson34/Documents/Projects/Legal_AI/Legal-OS/data/Freedom_Final_Asset_Agreement.pdf\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=start, completed=[]\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=ingestion_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: ingestion_agent\n",
      "INFO:app.orchestration.pipeline:Executing ingestion agent\n",
      "INFO:app.pipelines.ingestion_pipeline:Starting ingestion for: /Users/rbblankson34/Documents/Projects/Legal_AI/Legal-OS/data/Freedom_Final_Asset_Agreement.pdf\n",
      "INFO:app.pipelines.ingestion_pipeline:Loading document: /Users/rbblankson34/Documents/Projects/Legal_AI/Legal-OS/data/Freedom_Final_Asset_Agreement.pdf\n",
      "INFO:app.pipelines.ingestion_pipeline:Successfully loaded document Freedom_Final_Asset_Agreement.pdf (257988 chars, 84 pages/sections)\n",
      "INFO:app.rag.chunking:Chunking document 73bcc4da-afe9-4df2-83ec-077c13f3f3ff (length: 257988 chars)\n",
      "INFO:app.rag.chunking:Created 345 chunks for document 73bcc4da-afe9-4df2-83ec-077c13f3f3ff\n",
      "INFO:app.rag.chunking:Successfully created 345 chunks for document 73bcc4da-afe9-4df2-83ec-077c13f3f3ff\n",
      "INFO:app.rag.vector_store:Creating vectorstore from 345 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Running complete pipeline (this may take 2-4 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.rag.vector_store:Vectorstore created with 345 documents\n",
      "INFO:app.pipelines.ingestion_pipeline:Successfully ingested Freedom_Final_Asset_Agreement.pdf: 345 chunks stored\n",
      "INFO:app.orchestration.pipeline:Ingestion complete: 345 chunks created\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=clause_extraction, completed=['ingestion']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=clause_extraction_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: clause_extraction_agent\n",
      "INFO:app.orchestration.pipeline:Executing clause extraction agent\n",
      "INFO:app.agents.clause_extraction:Starting clause extraction for document_id=freedom_asset_agreement\n",
      "INFO:app.rag.retrievers:Creating naive retriever with k=10\n",
      "INFO:app.rag.retrievers:Creating naive retriever with k=10\n",
      "INFO:app.rag.retrievers:Creating naive retriever with k=10\n",
      "INFO:app.rag.vector_store:Creating retriever with search_kwargs: {'k': 10}\n",
      "INFO:app.rag.vector_store:Creating retriever with search_kwargs: {'k': 10}\n",
      "INFO:app.rag.vector_store:Creating retriever with search_kwargs: {'k': 10}\n",
      "INFO:app.agents.clause_extraction:Retriever created lazily with top_k=10\n",
      "INFO:app.agents.clause_extraction:Retriever created lazily with top_k=10\n",
      "INFO:app.agents.clause_extraction:Retriever created lazily with top_k=10\n",
      "INFO:app.agents.clause_extraction:Agent completed with 14 messages\n",
      "INFO:app.orchestration.pipeline:Clause extraction complete: 3 clauses, 5 red flags\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=risk_scoring, completed=['ingestion', 'clause_extraction']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=risk_scoring_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: risk_scoring_agent\n",
      "INFO:app.orchestration.pipeline:Executing risk scoring agent\n",
      "INFO:app.agents.risk_scoring:Starting risk scoring for document_id=freedom_asset_agreement\n",
      "INFO:app.agents.risk_scoring:Scoring 3 clauses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found clause: Payment Terms\n",
      "‚úÖ Found clause: Indemnification\n",
      "‚úÖ Found clause: Warranties\n",
      "‚úÖ Found red flag: High\n",
      "‚úÖ Found red flag: Medium\n",
      "‚úÖ Found red flag: Critical\n",
      "‚úÖ Found red flag: High\n",
      "‚úÖ Found red flag: Medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app.agents.risk_scoring:Agent completed with 15 messages\n",
      "INFO:app.agents.risk_scoring:‚úÖ Scored Payment Terms: 65 (High)\n",
      "INFO:app.agents.risk_scoring:‚úÖ Scored Indemnification: 65 (High)\n",
      "INFO:app.agents.risk_scoring:‚úÖ Scored Warranties: 65 (High)\n",
      "INFO:app.orchestration.pipeline:Risk scoring complete: 3 clauses scored, overall risk=65\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=summary, completed=['ingestion', 'clause_extraction', 'risk_scoring']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=summary_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: summary_agent\n",
      "INFO:app.orchestration.pipeline:Executing summary agent\n",
      "INFO:app.agents.summary:Starting summary generation for document_id=freedom_asset_agreement\n",
      "INFO:app.agents.summary:Processing 3 scored clauses\n",
      "INFO:app.agents.summary:Agent completed with 16 messages\n",
      "INFO:app.agents.summary:‚úÖ Summary generated: 3 clause summaries, 0 findings, 5 recommendations\n",
      "INFO:app.orchestration.pipeline:Summary complete: 0 findings, 5 recommendations\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=provenance, completed=['ingestion', 'clause_extraction', 'risk_scoring', 'summary']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=provenance_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: provenance_agent\n",
      "INFO:app.orchestration.pipeline:Executing provenance agent\n",
      "INFO:app.utils.source_tracker:SourceTracker initialized for document_id=freedom_asset_agreement\n",
      "INFO:app.orchestration.pipeline:Provenance tracking complete: 3 items tracked\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=checklist, completed=['ingestion', 'clause_extraction', 'risk_scoring', 'summary', 'provenance']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=checklist_agent\n",
      "INFO:app.orchestration.pipeline:Routing to: checklist_agent\n",
      "INFO:app.orchestration.pipeline:Executing checklist agent\n",
      "INFO:app.agents.checklist:Starting checklist generation\n",
      "INFO:app.agents.checklist:Invoking ReAct agent for checklist generation\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Legal\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Risk Management\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Operational\n",
      "INFO:app.agents.checklist:Generated 5 risk-based checklist items\n",
      "INFO:app.agents.checklist:Generated 5 standard checklist items for category: Financial\n",
      "INFO:app.agents.checklist:Generated 3 follow-up questions\n",
      "INFO:app.agents.checklist:Parsed 25 checklist items and 3 questions from agent messages\n",
      "INFO:app.agents.checklist:Checklist generation complete: 25 items, 3 questions in 16.99s\n",
      "INFO:app.orchestration.pipeline:Checklist complete: 25 questions generated\n",
      "INFO:app.orchestration.pipeline:Supervisor analyzing state: current_step=complete, completed=['ingestion', 'clause_extraction', 'risk_scoring', 'summary', 'provenance', 'checklist']\n",
      "INFO:app.orchestration.pipeline:Supervisor decision: next_agent=__end__\n",
      "INFO:app.orchestration.pipeline:Routing to: __end__\n",
      "INFO:app.orchestration.pipeline:Orchestration complete: 6 steps completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Orchestration Complete! (150.46s)\n",
      "   Status: completed\n",
      "   Steps: 6/6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.orchestration.pipeline import DocumentOrchestrator\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"END-TO-END ORCHESTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "orchestrator = DocumentOrchestrator(model_name=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "print(f\"\\nüöÄ Running complete pipeline (this may take 2-4 minutes)...\")\n",
    "orch_start = time.time()\n",
    "orch_results = orchestrator.run_orchestration(\n",
    "    document_path=str(sample_doc),\n",
    "    document_id=\"freedom_asset_agreement\"\n",
    ")\n",
    "orch_time = time.time() - orch_start\n",
    "\n",
    "print(f\"\\n‚úÖ Orchestration Complete! ({orch_time:.2f}s)\")\n",
    "print(f\"   Status: {orch_results['status']}\")\n",
    "print(f\"   Steps: {len(orch_results['completed_steps'])}/6\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975c35f",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Results & Export\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb78254",
   "metadata": {
    "title": "Results Summary"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PIPELINE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìä Sequential Workflow:\n",
      "   Total Time: 107.56s\n",
      "   - Ingestion: 8.91s\n",
      "   - RAG Test: 2.39s\n",
      "   - Clause Extraction: 37.74s\n",
      "   - Risk Scoring: 27.41s\n",
      "   - Summary: 22.98s\n",
      "   - Checklist: 8.14s\n",
      "\n",
      "üìä Orchestrated Workflow:\n",
      "   Total Time: 120.96s\n",
      "   Efficiency: -12.5% faster\n",
      "\n",
      "üìä Results:\n",
      "   Clauses Extracted: 3\n",
      "   Red Flags: 5\n",
      "   Overall Risk: 65/100\n",
      "   Findings: 0\n",
      "   Recommendations: 0\n",
      "   Checklist Items: 20\n",
      "\n",
      "üíæ Consolidated results saved to: combined_results.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ LEGAL-OS DEMONSTRATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated Files:\n",
      "   - diligence_memo_combined.md (Diligence memo)\n",
      "   - combined_results.json (Consolidated results)\n",
      "\n",
      "Key Achievements:\n",
      "   ‚úÖ Document ingestion with shared vector store\n",
      "   ‚úÖ RAG pipeline with question answering\n",
      "   ‚úÖ Clause extraction with red flag detection\n",
      "   ‚úÖ Risk scoring with categorization\n",
      "   ‚úÖ Diligence memo generation\n",
      "   ‚úÖ Source provenance tracking\n",
      "   ‚úÖ Checklist and follow-up questions\n",
      "   ‚úÖ End-to-end orchestration\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate total time for sequential workflow\n",
    "sequential_time = (ingestion_time + rag_time + clause_time + risk_time + \n",
    "                   summary_time + checklist_time)\n",
    "\n",
    "print(f\"\\nüìä Sequential Workflow:\")\n",
    "print(f\"   Total Time: {sequential_time:.2f}s\")\n",
    "print(f\"   - Ingestion: {ingestion_time:.2f}s\")\n",
    "print(f\"   - RAG Test: {rag_time:.2f}s\")\n",
    "print(f\"   - Clause Extraction: {clause_time:.2f}s\")\n",
    "print(f\"   - Risk Scoring: {risk_time:.2f}s\")\n",
    "print(f\"   - Summary: {summary_time:.2f}s\")\n",
    "print(f\"   - Checklist: {checklist_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nüìä Orchestrated Workflow:\")\n",
    "print(f\"   Total Time: {orch_time:.2f}s\")\n",
    "print(f\"   Efficiency: {((sequential_time - orch_time) / sequential_time * 100):.1f}% faster\")\n",
    "\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   Clauses Extracted: {len(clause_result.clauses)}\")\n",
    "print(f\"   Red Flags: {len(clause_result.red_flags)}\")\n",
    "print(f\"   Overall Risk: {risk_result.overall_risk_score}/100\")\n",
    "print(f\"   Findings: {len(memo.key_findings)}\")\n",
    "print(f\"   Recommendations: {len(memo.recommendations)}\")\n",
    "print(f\"   Checklist Items: {len(checklist_result.checklist_items)}\")\n",
    "\n",
    "# Export consolidated results\n",
    "export_data = {\n",
    "    \"document_id\": document_id,\n",
    "    \"document_name\": sample_doc.name,\n",
    "    \"processing_times\": {\n",
    "        \"sequential_total\": sequential_time,\n",
    "        \"orchestrated_total\": orch_time,\n",
    "        \"ingestion\": ingestion_time,\n",
    "        \"clause_extraction\": clause_time,\n",
    "        \"risk_scoring\": risk_time,\n",
    "        \"summary\": summary_time,\n",
    "        \"checklist\": checklist_time\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"clauses_extracted\": len(clause_result.clauses),\n",
    "        \"red_flags\": len(clause_result.red_flags),\n",
    "        \"overall_risk_score\": risk_result.overall_risk_score,\n",
    "        \"overall_risk_category\": risk_result.overall_risk_category,\n",
    "        \"findings\": len(memo.key_findings),\n",
    "        \"recommendations\": len(memo.recommendations),\n",
    "        \"checklist_items\": len(checklist_result.checklist_items),\n",
    "        \"follow_up_questions\": len(checklist_result.follow_up_questions)\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = backend_path / \"combined_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(export_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüíæ Consolidated results saved to: {results_path.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ LEGAL-OS DEMONSTRATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(f\"   - {memo_path.name} (Diligence memo)\")\n",
    "print(f\"   - {results_path.name} (Consolidated results)\")\n",
    "print(\"\\nKey Achievements:\")\n",
    "print(\"   ‚úÖ Document ingestion with shared vector store\")\n",
    "print(\"   ‚úÖ RAG pipeline with question answering\")\n",
    "print(\"   ‚úÖ Clause extraction with red flag detection\")\n",
    "print(\"   ‚úÖ Risk scoring with categorization\")\n",
    "print(\"   ‚úÖ Diligence memo generation\")\n",
    "print(\"   ‚úÖ Source provenance tracking\")\n",
    "print(\"   ‚úÖ Checklist and follow-up questions\")\n",
    "print(\"   ‚úÖ End-to-end orchestration\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
